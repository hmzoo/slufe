import { editSingleImage, editImage } from './imageEditor.js';
import { generateVideo } from './videoGenerator.js';
import { generateVideoFromImage } from './videoImageGenerator.js';
import { saveCompleteOperation } from './dataStorage.js';

/**
 * Orchestrateur de workflows multi-√©tapes
 * G√®re l'ex√©cution s√©quentielle des √©tapes et la sauvegarde des r√©sultats interm√©diaires
 */

/**
 * Ex√©cute un workflow multi-√©tapes
 * 
 * @param {Object} workflow - Configuration du workflow
 * @param {Object} context - Contexte d'ex√©cution
 * @param {string} context.prompt - Prompt principal
 * @param {string} context.optimizedPrompt - Prompt optimis√© (optionnel)
 * @param {string[]} context.stepPrompts - Prompts sp√©cifiques pour chaque √©tape (optionnel)
 * @param {Array} context.imageBuffers - Buffers des images
 * @param {Object} context.parameters - Param√®tres de g√©n√©ration
 * @returns {Promise<Object>} - R√©sultat complet du workflow
 */
export async function executeMultiStepWorkflow(workflow, context) {
  console.log(`\nüöÄ D√©marrage workflow: ${workflow.name}`);
  console.log(`üìù Prompt: ${context.prompt}`);
  console.log(`üìã Nombre d'√©tapes: ${workflow.steps.length}`);

  const results = {
    workflowId: workflow.id,
    workflowName: workflow.name,
    steps: [],
    finalResult: null,
    success: false,
    error: null
  };

  try {
    const { prompt, optimizedPrompt, stepPrompts = [], imageBuffers, parameters } = context;

    // Pr√©parer l'entr√©e pour la premi√®re √©tape
    let currentInput = {
      prompt: optimizedPrompt || prompt,
      imageBuffers,
      images: [],
      parameters
    };

    // Ex√©cuter chaque √©tape s√©quentiellement
    for (let i = 0; i < workflow.steps.length; i++) {
      const step = workflow.steps[i];
      console.log(`\nüìç √âtape ${i + 1}/${workflow.steps.length}: ${step.name}`);

      // Utiliser le prompt sp√©cifique de l'√©tape si fourni par l'analyseur
      if (stepPrompts[i]) {
        console.log(`  üéØ Utilisation du prompt sp√©cifique pour l'√©tape ${i + 1}`);
        currentInput.stepPrompt = stepPrompts[i];
      }

      const stepResult = await executeStep(step, currentInput, i + 1, stepPrompts[i]);
      
      results.steps.push(stepResult);

      // Sauvegarder le r√©sultat interm√©diaire
      try {
        await saveStepResult(stepResult, workflow, prompt, parameters);
      } catch (saveError) {
        console.warn(`‚ö†Ô∏è Erreur sauvegarde √©tape ${i + 1}:`, saveError.message);
      }

      // Pr√©parer l'entr√©e pour l'√©tape suivante
      if (stepResult.success && stepResult.outputUrl) {
        currentInput = {
          ...currentInput,
          resultFromPreviousStep: stepResult.outputUrl,
          // Pour les √©tapes vid√©o, on peut r√©utiliser l'image √©dit√©e
          images: stepResult.type === 'image' ? [stepResult.outputUrl] : currentInput.images
        };
      } else {
        throw new Error(`√âchec de l'√©tape ${i + 1}: ${stepResult.error}`);
      }
    }

    // Le r√©sultat final est celui de la derni√®re √©tape
    results.finalResult = results.steps[results.steps.length - 1];
    results.success = true;

    console.log(`\n‚úÖ Workflow ${workflow.name} termin√© avec succ√®s`);
    console.log(`üìä ${results.steps.length} √©tapes ex√©cut√©es`);

    return results;

  } catch (error) {
    console.error(`‚ùå Erreur workflow ${workflow.name}:`, error);
    results.error = error.message;
    results.success = false;
    throw error;
  }
}

/**
 * Ex√©cute une √©tape individuelle du workflow
 * 
 * @param {Object} step - Configuration de l'√©tape
 * @param {Object} input - Donn√©es d'entr√©e
 * @param {number} stepNumber - Num√©ro de l'√©tape
 * @param {string} specificPrompt - Prompt sp√©cifique pour cette √©tape (optionnel)
 * @returns {Promise<Object>} - R√©sultat de l'√©tape
 */
async function executeStep(step, input, stepNumber, specificPrompt = null) {
  const startTime = Date.now();
  
  // D√©terminer le prompt √† utiliser pour cette √©tape
  // Priorit√©: 1. prompt sp√©cifique de l'analyseur, 2. transformation du prompt, 3. prompt brut
  let promptForStep;
  if (specificPrompt) {
    promptForStep = specificPrompt;
    console.log(`  üéØ Utilisation du prompt fourni par l'analyseur`);
  } else if (step.promptTransform) {
    promptForStep = step.promptTransform(input.prompt);
    console.log(`  üîÑ Transformation du prompt par le workflow`);
  } else {
    promptForStep = input.prompt;
    console.log(`  üìã Utilisation du prompt brut`);
  }
  
  const stepResult = {
    stepNumber: stepNumber,
    name: step.name,
    type: step.type, // 'image' ou 'video'
    service: step.service,
    method: step.method,
    prompt: promptForStep,
    outputUrl: null,
    duration: null,
    success: false,
    error: null
  };

  try {
    console.log(`  üìù Prompt pour cette √©tape: "${stepResult.prompt}"`);
    console.log(`  üîß Service: ${step.service}, M√©thode: ${step.method}`);
    console.log(`  üì¶ Input imageBuffers: ${input.imageBuffers?.length || 0}, images: ${input.images?.length || 0}`);
    
    global.logWorkflow?.(`STEP ${stepNumber} START`, {
      service: step.service,
      method: step.method,
      prompt: stepResult.prompt,
      hasImageBuffers: !!input.imageBuffers,
      imageBuffersCount: input.imageBuffers?.length || 0,
      hasImages: !!input.images,
      imagesCount: input.images?.length || 0,
      parameters: input.parameters
    });
    
    let result;

    // Ex√©cuter selon le type d'√©tape
    switch (step.service) {
      case 'imageEditor':
        console.log(`  ‚úèÔ∏è Ex√©cution de l'√©dition d'image...`);
        result = await executeImageEditStep(step, input, stepResult.prompt);
        console.log(`  ‚úÖ √âdition termin√©e:`, result);
        global.logWorkflow?.(`STEP ${stepNumber} IMAGE EDIT RESULT`, result);
        stepResult.type = 'image';
        break;

      case 'videoGenerator':
        result = await executeVideoGenerationStep(step, input, stepResult.prompt);
        stepResult.type = 'video';
        break;

      case 'videoImageGenerator':
        result = await executeImageToVideoStep(step, input, stepResult.prompt);
        stepResult.type = 'video';
        break;

      default:
        throw new Error(`Service non support√©: ${step.service}`);
    }

    // Extraire l'URL du r√©sultat (format variable selon le service)
    stepResult.outputUrl = result.url || result.imageUrl || result.videoUrl || 
                           (result.imageUrls && result.imageUrls[0]) ||
                           (result.videoUrls && result.videoUrls[0]);
    
    if (!stepResult.outputUrl) {
      console.warn('‚ö†Ô∏è  Aucune URL trouv√©e dans le r√©sultat:', result);
      throw new Error('Le service n\'a retourn√© aucune URL de r√©sultat');
    }
    
    stepResult.success = true;
    stepResult.duration = Date.now() - startTime;

    console.log(`  ‚úÖ √âtape termin√©e en ${stepResult.duration}ms`);
    console.log(`  üîó R√©sultat: ${stepResult.outputUrl}`);
    
    global.logWorkflow?.(`STEP ${stepNumber} SUCCESS`, {
      outputUrl: stepResult.outputUrl,
      duration: stepResult.duration,
      type: stepResult.type
    });

    return stepResult;

  } catch (error) {
    console.error(`  ‚ùå Erreur √©tape ${stepNumber}:`, error);
    stepResult.error = error.message;
    stepResult.duration = Date.now() - startTime;
    
    global.logWorkflow?.(`STEP ${stepNumber} ERROR`, {
      error: error.message,
      stack: error.stack,
      duration: stepResult.duration
    });
    
    throw error;
  }
}

/**
 * Ex√©cute une √©tape d'√©dition d'image
 */
async function executeImageEditStep(step, input, prompt) {
  const { images, imageBuffers, parameters } = input;

  console.log(`    üîç executeImageEditStep - imageBuffers: ${imageBuffers?.length || 0}, images: ${images?.length || 0}`);
  
  // Nettoyer et convertir les param√®tres en types corrects
  const cleanParams = {
    aspectRatio: parameters?.aspectRatio || '16:9',
    outputFormat: parameters?.outputFormat || 'webp',
    outputQuality: parseInt(parameters?.outputQuality) || 90,
    goFast: parameters?.goFast !== false,
    seed: parameters?.seed ? parseInt(parameters.seed) : null
  };
  
  console.log(`    üßπ Param√®tres nettoy√©s:`, cleanParams);

  if (imageBuffers && imageBuffers.length > 0) {
    // Utiliser les buffers si disponibles
    const imageDataUrls = imageBuffers.map(buffer => {
      const base64 = buffer.toString('base64');
      return `data:image/jpeg;base64,${base64}`;
    });

    console.log(`    üì∏ Images converties en data URLs (${imageDataUrls.length})`);

    if (imageDataUrls.length === 1) {
      console.log(`    üéØ √âdition image unique avec prompt: "${prompt.substring(0, 60)}..."`);
      const result = await editSingleImage({
        prompt,
        imageUrl: imageDataUrls[0],
        ...cleanParams
      });
      console.log(`    ‚úÖ R√©sultat √©dition:`, result);
      return result;
    } else {
      return await editImage({
        prompt,
        images: imageDataUrls,
        ...cleanParams
      });
    }
  } else if (images && images.length > 0) {
    // Utiliser les URLs
    if (images.length === 1) {
      return await editSingleImage({
        prompt,
        imageUrl: images[0],
        ...cleanParams
      });
    } else {
      return await editImage({
        prompt,
        images: images,
        ...cleanParams
      });
    }
  }

  throw new Error('Aucune image fournie pour l\'√©dition');
}

/**
 * Ex√©cute une √©tape de g√©n√©ration de vid√©o
 */
async function executeVideoGenerationStep(step, input, prompt) {
  const { parameters } = input;

  return await generateVideo({
    prompt,
    ...parameters
  });
}

/**
 * Ex√©cute une √©tape de conversion image vers vid√©o
 */
async function executeImageToVideoStep(step, input, prompt) {
  const { images, resultFromPreviousStep, parameters } = input;

  // Utiliser le r√©sultat de l'√©tape pr√©c√©dente si disponible
  const imageToAnimate = resultFromPreviousStep || (images && images[0]);

  if (!imageToAnimate) {
    throw new Error('Aucune image fournie pour l\'animation');
  }

  console.log(`  üñºÔ∏è  Image source: ${imageToAnimate.substring(0, 100)}...`);

  // Pr√©parer les param√®tres pour la g√©n√©ration de vid√©o
  // Note: numFrames doit √™tre entre 81 et 121, resolution doit √™tre "480p" ou "720p"
  const videoParams = {
    prompt,
    image: imageToAnimate, // generateVideoFromImage attend 'image'
    aspectRatio: parameters.aspectRatio || '16:9',
    numFrames: Math.max(81, Math.min(121, parameters.numFrames || 81)), // Clamp entre 81 et 121
    resolution: parameters.resolution === 720 ? '720p' : '480p', // Convertir nombre en string
    seed: parameters.seed || null
  };

  return await generateVideoFromImage(videoParams);
}

/**
 * Sauvegarde le r√©sultat d'une √©tape
 */
async function saveStepResult(stepResult, workflow, originalPrompt, parameters) {
  if (!stepResult.success || !stepResult.outputUrl) {
    return;
  }

  await saveCompleteOperation({
    operationType: `${workflow.id}_step_${stepResult.stepNumber}`,
    prompt: stepResult.prompt,
    parameters: {
      ...parameters,
      workflowId: workflow.id,
      workflowName: workflow.name,
      stepNumber: stepResult.stepNumber,
      stepName: stepResult.name,
      originalPrompt: originalPrompt
    },
    inputImages: [], // Les images sont d√©j√† dans l'√©tape pr√©c√©dente
    resultUrl: stepResult.outputUrl,
    workflowAnalysis: {
      workflow: {
        id: workflow.id,
        name: workflow.name
      },
      step: {
        number: stepResult.stepNumber,
        name: stepResult.name,
        type: stepResult.type
      }
    },
    error: null
  });

  console.log(`  üíæ R√©sultat de l'√©tape ${stepResult.stepNumber} sauvegard√©`);
}

/**
 * Workflows pr√©d√©finis multi-√©tapes
 */
export const MULTI_STEP_WORKFLOWS = {
  EDIT_THEN_VIDEO: {
    id: 'edit_then_video',
    name: '√âdition puis vid√©o',
    description: '√âditer l\'image puis cr√©er une vid√©o anim√©e',
    steps: [
      {
        name: '√âdition de l\'image',
        service: 'imageEditor',
        method: 'editSingleImage',
        type: 'image',
        promptTransform: (prompt) => {
          // Extraire la partie √©dition du prompt
          // Ex: "√©dite cette image pour ajouter un coucher de soleil puis anime-la"
          // -> "ajouter un coucher de soleil"
          const editKeywords = ['√©dite', 'modifie', 'change', 'transforme', 'ajoute', 'enl√®ve'];
          for (const keyword of editKeywords) {
            if (prompt.toLowerCase().includes(keyword)) {
              // Prendre tout jusqu'√† "puis" ou "ensuite"
              const parts = prompt.toLowerCase().split(/puis|ensuite|apr√®s/);
              if (parts.length > 1) {
                return parts[0].trim();
              }
            }
          }
          return prompt;
        }
      },
      {
        name: 'Animation en vid√©o',
        service: 'videoImageGenerator',
        method: 'generateVideoFromImage',
        type: 'video',
        promptTransform: (prompt) => {
          // Extraire la partie animation du prompt
          // Ex: "√©dite cette image pour ajouter un coucher de soleil puis anime-la avec des mouvements de cam√©ra"
          // -> "des mouvements de cam√©ra"
          const parts = prompt.toLowerCase().split(/puis|ensuite|apr√®s/);
          if (parts.length > 1) {
            return parts[1].trim();
          }
          // Par d√©faut, cr√©er un prompt d'animation g√©n√©rique
          return 'anime cette image avec des mouvements fluides';
        }
      }
    ]
  }
};

/**
 * D√©termine si un workflow n√©cessite plusieurs √©tapes
 */
export function isMultiStepWorkflow(workflowId) {
  return Object.values(MULTI_STEP_WORKFLOWS).some(wf => wf.id === workflowId);
}

/**
 * R√©cup√®re la configuration d'un workflow multi-√©tapes
 */
export function getMultiStepWorkflow(workflowId) {
  return Object.values(MULTI_STEP_WORKFLOWS).find(wf => wf.id === workflowId) || null;
}
