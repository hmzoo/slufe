import Replicate from 'replicate';
import { DEFAULT_REPLICATE_OPTIONS } from '../config/replicate.js';

/**
 * Service d'analyse de workflow intelligent
 * D√©termine automatiquement le meilleur workflow √† utiliser en fonction du prompt et des images
 */

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

/**
 * Liste des workflows disponibles
 */
export const AVAILABLE_WORKFLOWS = {
  TEXT_TO_IMAGE: {
    id: 'text_to_image',
    name: 'G√©n√©ration d\'image simple',
    description: 'Cr√©er une image √† partir d\'un prompt texte',
    requires: { prompt: true, images: 0 },
    service: 'imageGenerator',
    method: 'generateImage'
  },
  TEXT_TO_VIDEO: {
    id: 'text_to_video',
    name: 'G√©n√©ration de vid√©o simple',
    description: 'Cr√©er une vid√©o √† partir d\'un prompt texte',
    requires: { prompt: true, images: 0 },
    service: 'videoGenerator',
    method: 'generateVideo'
  },
  IMAGE_EDIT_SINGLE: {
    id: 'image_edit_single',
    name: '√âdition d\'image unique',
    description: 'Modifier une image selon les instructions',
    requires: { prompt: true, images: 1 },
    service: 'imageEditor',
    method: 'editSingleImage'
  },
  IMAGE_EDIT_MULTIPLE: {
    id: 'image_edit_multiple',
    name: '√âdition d\'images multiples',
    description: 'Combiner ou fusionner plusieurs images',
    requires: { prompt: true, images: 2 },
    service: 'imageEditor',
    method: 'editImage'
  },
  IMAGE_TO_VIDEO_SINGLE: {
    id: 'image_to_video_single',
    name: 'Vid√©o depuis image de d√©part',
    description: 'Animer une image de d√©part',
    requires: { prompt: true, images: 1 },
    service: 'videoImageGenerator',
    method: 'generateVideoFromImage'
  },
  IMAGE_TO_VIDEO_TRANSITION: {
    id: 'image_to_video_transition',
    name: 'Vid√©o transition entre deux images',
    description: 'Cr√©er une transition/morphing entre deux images',
    requires: { prompt: true, images: 2 },
    service: 'videoImageGenerator',
    method: 'generateVideoFromImage'
  },
  EDIT_THEN_VIDEO: {
    id: 'edit_then_video',
    name: '√âdition puis vid√©o',
    description: '√âditer l\'image puis cr√©er une vid√©o avec transition',
    requires: { prompt: true, images: [1, 2] }, // Accepte 1 ou 2 images
    service: 'composite',
    steps: ['imageEditor', 'videoImageGenerator']
  }
};

/**
 * Analyse le contexte pour d√©terminer le workflow appropri√©
 * 
 * @param {Object} context - Contexte de la requ√™te
 * @param {string} context.prompt - Prompt de l'utilisateur
 * @param {number} context.imageCount - Nombre d'images fournies
 * @param {string[]} context.imageDescriptions - Descriptions des images (optionnel)
 * @returns {Promise<Object>} - R√©sultat de l'analyse avec workflow et prompts optimis√©s
 */
export async function analyzeWorkflow(context) {
  const { prompt, imageCount = 0, imageDescriptions = [] } = context;

  if (!prompt || !prompt.trim()) {
    throw new Error('Le prompt est requis pour l\'analyse');
  }

  console.log('üîç Analyse du workflow...');
  console.log('üìù Prompt:', prompt);
  console.log('üñºÔ∏è  Images:', imageCount);
  console.log('üìã imageDescriptions re√ßues:', imageDescriptions);
  console.log('üìä Nombre de descriptions:', imageDescriptions.length);
  if (imageDescriptions.length > 0) {
    console.log('üìã Descriptions disponibles:', imageDescriptions.length);
    console.log('üìù Premi√®re description (aper√ßu):', imageDescriptions[0]?.substring(0, 100) + '...');
  }

  // Utiliser Gemini via Replicate pour l'analyse
  return performReplicateAnalysis(prompt, imageCount, imageDescriptions);
}

/**
 * Analyse avec Gemini via Replicate
 */
async function performReplicateAnalysis(prompt, imageCount, imageDescriptions = []) {
  try {
    console.log('üîÑ Utilisation de Gemini 2.5 Flash via Replicate...');

    // Construire le contexte des images si disponible
    let imageContext = '';
    if (imageDescriptions.length > 0) {
      imageContext = '\n\nImage descriptions:\n' + 
        imageDescriptions.map((desc, i) => `Image ${i + 1}: ${desc}`).join('\n');
      console.log('üìã Descriptions d\'images ajout√©es au contexte:', imageDescriptions.length);
    }

    const systemInstruction = `You are an AI workflow analyzer for a creative content generation platform. Your role is to analyze user requests and determine the best workflow to use.

Available workflows:
1. TEXT_TO_IMAGE - Generate image from text prompt (requires 0 images)
2. TEXT_TO_VIDEO - Generate video from text prompt (requires 0 images)
3. IMAGE_EDIT_SINGLE - Edit a single image based on instructions (requires 1 image)
4. IMAGE_EDIT_MULTIPLE - Combine or merge multiple images (requires 2+ images)
5. IMAGE_TO_VIDEO_SINGLE - Animate a single image (requires 1 image)
6. IMAGE_TO_VIDEO_TRANSITION - Create transition between images (requires 2 images)
7. EDIT_THEN_VIDEO - Edit image(s) then create video (requires 1-2 images) - REQUIRES STEP SPLITTING

CRITICAL: For EDIT_THEN_VIDEO workflow, you MUST provide separate prompts for each step:
- step1Prompt: Instructions ONLY for editing the image (what to add/modify/change)
- step2Prompt: Instructions ONLY for animating the video (camera movements, motion, animation style)

Example for "√©dite cette image pour ajouter un coucher de soleil puis anime-la avec des mouvements de cam√©ra":
{
  "workflow": "EDIT_THEN_VIDEO",
  "step1Prompt": "Add a vibrant sunset with warm hues, dramatic orange and pink sky, golden light",
  "step2Prompt": "Animate with smooth camera movements: slow pan left to right, gentle zoom emphasizing the sunset"
}

CRITICAL DETECTION RULES FOR EDIT_THEN_VIDEO:
- Use EDIT_THEN_VIDEO when the prompt mentions BOTH editing AND creating video/animation
- Keywords that indicate EDIT_THEN_VIDEO: "et genere un film", "et cree une video", "puis anime", "puis video", "then create video", "then animate"
- Examples:
  * "place les deux personnages dans un caf√© et genere un film" ‚Üí EDIT_THEN_VIDEO
  * "Change background to beach then create video" ‚Üí EDIT_THEN_VIDEO
  * "√©dite pour ajouter un coucher de soleil puis anime" ‚Üí EDIT_THEN_VIDEO

IMPORTANT: 
- When image descriptions are provided, USE THEM to understand context
- Keep the optimizedPrompt CONCISE (max 150 words) while incorporating key details from image descriptions
- Focus on the most important visual elements

Based on the user prompt and number of images provided, determine the most appropriate workflow.

Respond ONLY with a JSON object in this exact format (NO markdown code blocks, just raw JSON):
{
  "workflow": "WORKFLOW_ID",
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation (max 50 words)",
  "optimizedPrompt": "improved prompt incorporating image details (max 150 words)",
  "step1Prompt": "REQUIRED for EDIT_THEN_VIDEO: editing instructions only",
  "step2Prompt": "REQUIRED for EDIT_THEN_VIDEO: animation instructions only",
  "suggestions": ["suggestion 1", "suggestion 2"]
}`;

    const userPrompt = `User prompt: "${prompt}"
Number of images provided: ${imageCount}${imageContext}

Analyze and respond with the JSON workflow recommendation:`;

    console.log('üì§ Prompt envoy√© √† Gemini (Replicate):', userPrompt);

    // Appel √† Gemini via Replicate
    const output = await replicate.run(
      'google/gemini-2.5-flash',
      {
        input: {
          system_instruction: systemInstruction,
          prompt: userPrompt,
          max_output_tokens: 1024,
          temperature: 0.3,
          top_p: 0.95,
          dynamic_thinking: false,
        },
        ...DEFAULT_REPLICATE_OPTIONS
      }
    );

    console.log('üîç Type de output:', typeof output);
    console.log('üîç Output brut:', JSON.stringify(output).substring(0, 200));

    // Extraire le texte de la r√©ponse
    let responseText = '';
    if (Array.isArray(output)) {
      console.log('üìã Output est un array de longueur:', output.length);
      responseText = output.join('');
    } else if (typeof output === 'string') {
      console.log('üìã Output est une string');
      responseText = output;
    } else {
      console.log('üìã Output est un objet:', Object.keys(output || {}));
      responseText = String(output);
    }

    console.log('üìÑ Replicate Gemini response:', responseText);

    // Parser la r√©ponse JSON
    let analysis;
    try {
      // Nettoyer la r√©ponse des backticks markdown
      let cleanedText = responseText.trim();
      
      // Retirer les blocs markdown ```json ... ```
      cleanedText = cleanedText.replace(/```json\s*/g, '').replace(/```\s*/g, '');
      
      console.log('üßπ Texte nettoy√© (premiers 300 chars):', cleanedText.substring(0, 300));
      
      // Extraire le JSON
      const jsonMatch = cleanedText.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        console.log('‚úÖ JSON trouv√©, tentative de parsing...');
        analysis = JSON.parse(jsonMatch[0]);
        console.log('‚úÖ JSON pars√© avec succ√®s:', analysis.workflow);
      } else {
        throw new Error('No JSON found in response after cleaning');
      }
    } catch (parseError) {
      console.error('‚ùå Erreur parsing JSON:', parseError);
      console.error('üìÑ R√©ponse brute de Gemini:', responseText.substring(0, 500));
      console.log('‚ö†Ô∏è  FALLBACK: Utilisation de l\'analyse basique (r√®gles heuristiques)');
      return performBasicAnalysis(prompt, imageCount, imageDescriptions);
    }

    // Valider et enrichir l'analyse
    const workflow = AVAILABLE_WORKFLOWS[analysis.workflow];
    if (!workflow) {
      console.warn('‚ö†Ô∏è  Workflow invalide d√©tect√©, fallback to basic analysis');
      return performBasicAnalysis(prompt, imageCount, imageDescriptions);
    }

    // V√©rifier la compatibilit√© avec le nombre d'images
    const imagesRequired = workflow.requires.images;
    const isValidImageCount = Array.isArray(imagesRequired)
      ? imagesRequired.includes(imageCount) // Accepte une liste de valeurs [1, 2]
      : imagesRequired === imageCount;       // Accepte une valeur exacte
    
    if (!isValidImageCount) {
      const expectedText = Array.isArray(imagesRequired)
        ? `${imagesRequired.join(' ou ')} image(s)`
        : `${imagesRequired} image(s)`;
      
      console.warn(`‚ö†Ô∏è  Workflow n√©cessite ${expectedText} mais ${imageCount} fournie(s)`);
      return {
        success: false,
        error: `Ce workflow n√©cessite ${expectedText}, mais vous en avez fourni ${imageCount}`,
        suggestedWorkflow: getSuggestedWorkflow(imageCount)
      };
    }

    console.log('‚úÖ Workflow d√©termin√© (via Replicate):', workflow.name);
    console.log('üí° Confiance:', analysis.confidence);

    // Pour les workflows multi-√©tapes, g√©n√©rer les prompts s√©par√©s si Gemini ne les a pas fournis
    let step1Prompt = analysis.step1Prompt || null;
    let step2Prompt = analysis.step2Prompt || null;

    if (workflow.id === 'edit_then_video' && (!step1Prompt || !step2Prompt)) {
      console.log('üîÑ Gemini (Replicate) n\'a pas fourni les prompts s√©par√©s, g√©n√©ration automatique...');
      const splitPrompts = splitMultiStepPrompt(prompt, analysis.optimizedPrompt || prompt);
      step1Prompt = step1Prompt || splitPrompts.step1;
      step2Prompt = step2Prompt || splitPrompts.step2;
      console.log(`  üìù Step 1: "${step1Prompt}"`);
      console.log(`  üìù Step 2: "${step2Prompt}"`);
    }

    return {
      success: true,
      workflow: {
        id: workflow.id,
        name: workflow.name,
        description: workflow.description,
        service: workflow.service,
        method: workflow.method,
        steps: workflow.steps
      },
      analysis: {
        confidence: analysis.confidence,
        reasoning: analysis.reasoning,
        suggestions: analysis.suggestions || []
      },
      prompts: {
        original: prompt,
        optimized: analysis.optimizedPrompt || prompt,
        // Pour les workflows multi-√©tapes, inclure les prompts s√©par√©s
        step1: step1Prompt,
        step2: step2Prompt
      },
      requirements: {
        imagesNeeded: Array.isArray(workflow.requires.images) 
          ? workflow.requires.images.join(' ou ')
          : workflow.requires.images,
        imagesProvided: imageCount,
        satisfied: Array.isArray(workflow.requires.images)
          ? workflow.requires.images.includes(imageCount)
          : workflow.requires.images <= imageCount
      },
      imageDescriptions: imageDescriptions || []
    };

  } catch (error) {
    console.error('‚ùå Erreur lors de l\'analyse via Replicate:', error);
    console.error('üìä D√©tails:', {
      message: error.message,
      stack: error.stack?.substring(0, 200)
    });
    console.log('‚ö†Ô∏è  FALLBACK: Utilisation de l\'analyse basique (r√®gles heuristiques)');
    return performBasicAnalysis(prompt, imageCount, imageDescriptions);
  }
}

/**
 * Divise un prompt multi-√©tapes en prompts s√©par√©s pour chaque √©tape
 * Utilis√© quand Gemini ne fournit pas step1Prompt et step2Prompt
 */
function splitMultiStepPrompt(originalPrompt, optimizedPrompt) {
  const lowerPrompt = originalPrompt.toLowerCase();
  
  // Mots-cl√©s qui s√©parent les √©tapes
  const separators = ['puis', 'ensuite', 'apr√®s', 'then', 'after', 'followed by'];
  
  // Trouver le s√©parateur dans le prompt
  let separatorIndex = -1;
  let usedSeparator = '';
  for (const sep of separators) {
    const index = lowerPrompt.indexOf(sep);
    if (index !== -1 && (separatorIndex === -1 || index < separatorIndex)) {
      separatorIndex = index;
      usedSeparator = sep;
    }
  }
  
  if (separatorIndex === -1) {
    // Pas de s√©parateur trouv√©, diviser le prompt optimis√© en deux
    const words = optimizedPrompt.split(' ');
    const midpoint = Math.floor(words.length / 2);
    return {
      step1: words.slice(0, midpoint).join(' '),
      step2: words.slice(midpoint).join(' ')
    };
  }
  
  // Extraire les deux parties
  const part1 = originalPrompt.substring(0, separatorIndex).trim();
  const part2 = originalPrompt.substring(separatorIndex + usedSeparator.length).trim();
  
  // Nettoyer les parties pour enlever les r√©f√©rences √† "cette image" etc.
  let step1 = part1
    .replace(/√©dite\s+cette\s+image\s+(pour\s+)?/i, '')
    .replace(/modifie\s+cette\s+image\s+(pour\s+)?/i, '')
    .replace(/edit\s+this\s+image\s+(to\s+)?/i, '')
    .replace(/modify\s+this\s+image\s+(to\s+)?/i, '')
    .trim();
    
  let step2 = part2
    .replace(/anime[-\s]la/i, 'animate the image')
    .replace(/cr√©er?\s+une?\s+vid√©o/i, 'create a video')
    .replace(/^et\s+/i, '')
    .trim();
  
  // Si step1 ou step2 sont trop courts, utiliser le prompt optimis√© comme base
  if (step1.length < 10) {
    step1 = optimizedPrompt.split('.')[0] || optimizedPrompt.substring(0, optimizedPrompt.length / 2);
  }
  
  if (step2.length < 10) {
    step2 = 'Animate the edited image with smooth movements';
  }
  
  return {
    step1: step1,
    step2: step2
  };
}

/**
 * Analyse basique sans IA (fallback)
 */
function performBasicAnalysis(prompt, imageCount, imageDescriptions = []) {
  const lowerPrompt = prompt.toLowerCase();
  
  // D√©tection de mots-cl√©s vid√©o
  const videoKeywords = ['video', 'vid√©o', 'animate', 'animer', 'animation', 'moving', 'motion', 'mouvement'];
  const hasVideoKeyword = videoKeywords.some(kw => lowerPrompt.includes(kw));
  
  // D√©tection de mots-cl√©s √©dition
  const editKeywords = ['edit', '√©diter', 'modify', 'modifier', 'change', 'changer', 'transform', 'transformer', 'combine', 'fusionner', 'merge'];
  const hasEditKeyword = editKeywords.some(kw => lowerPrompt.includes(kw));

  let selectedWorkflow;

  // Logique de s√©lection
  if (imageCount === 0) {
    selectedWorkflow = hasVideoKeyword ? AVAILABLE_WORKFLOWS.TEXT_TO_VIDEO : AVAILABLE_WORKFLOWS.TEXT_TO_IMAGE;
  } else if (imageCount === 1) {
    if (hasVideoKeyword && hasEditKeyword) {
      selectedWorkflow = AVAILABLE_WORKFLOWS.EDIT_THEN_VIDEO;
    } else if (hasVideoKeyword) {
      selectedWorkflow = AVAILABLE_WORKFLOWS.IMAGE_TO_VIDEO_SINGLE;
    } else {
      selectedWorkflow = AVAILABLE_WORKFLOWS.IMAGE_EDIT_SINGLE;
    }
  } else {
    if (hasVideoKeyword) {
      selectedWorkflow = AVAILABLE_WORKFLOWS.IMAGE_TO_VIDEO_TRANSITION;
    } else {
      selectedWorkflow = AVAILABLE_WORKFLOWS.IMAGE_EDIT_MULTIPLE;
    }
  }

  return {
    success: true,
    workflow: {
      id: selectedWorkflow.id,
      name: selectedWorkflow.name,
      description: selectedWorkflow.description,
      service: selectedWorkflow.service,
      method: selectedWorkflow.method,
      steps: selectedWorkflow.steps
    },
    analysis: {
      confidence: 0.7,
      reasoning: 'Analyse bas√©e sur des mots-cl√©s (mode fallback - Gemini n\'a pas pu g√©n√©rer une r√©ponse valide)',
      suggestions: [
        'L\'analyse IA a √©chou√©, utilisation des r√®gles heuristiques de base',
        'V√©rifiez que REPLICATE_API_TOKEN est correctement configur√© dans le fichier .env'
      ]
    },
    prompts: {
      original: prompt,
      optimized: prompt // Pas d'optimisation en mode fallback
    },
    requirements: {
      imagesNeeded: Array.isArray(selectedWorkflow.requires.images) 
        ? selectedWorkflow.requires.images.join(' ou ')
        : selectedWorkflow.requires.images,
      imagesProvided: imageCount,
      satisfied: Array.isArray(selectedWorkflow.requires.images)
        ? selectedWorkflow.requires.images.includes(imageCount)
        : selectedWorkflow.requires.images <= imageCount
    },
    imageDescriptions: imageDescriptions || [],
    mock: true,
    fallback: true,
    warning: 'Analyse basique utilis√©e - L\'IA n\'a pas pu analyser correctement votre demande'
  };
}

/**
 * Sugg√®re un workflow alternatif bas√© sur le nombre d'images
 */
function getSuggestedWorkflow(imageCount) {
  if (imageCount === 0) {
    return {
      workflow: AVAILABLE_WORKFLOWS.TEXT_TO_IMAGE,
      message: 'Vous pouvez g√©n√©rer une image √† partir de votre prompt'
    };
  } else if (imageCount === 1) {
    return {
      workflow: AVAILABLE_WORKFLOWS.IMAGE_EDIT_SINGLE,
      message: 'Vous pouvez √©diter votre image ou cr√©er une vid√©o √† partir d\'elle'
    };
  } else {
    return {
      workflow: AVAILABLE_WORKFLOWS.IMAGE_EDIT_MULTIPLE,
      message: 'Vous pouvez combiner vos images ou cr√©er une transition vid√©o'
    };
  }
}

/**
 * Obtenir des exemples de prompts pour chaque workflow
 */
export function getWorkflowExamples() {
  return {
    TEXT_TO_IMAGE: [
      'A serene mountain landscape at golden hour',
      'Professional portrait of a business woman in office',
      'Futuristic cityscape with neon lights'
    ],
    TEXT_TO_VIDEO: [
      'Ocean waves crashing on shore at sunset',
      'Time-lapse of clouds moving across sky',
      'Camera slowly panning across a forest'
    ],
    IMAGE_EDIT_SINGLE: [
      'Change the background to a beach at sunset',
      'Transform into watercolor painting style',
      'Add dramatic lighting and cinematic atmosphere'
    ],
    IMAGE_EDIT_MULTIPLE: [
      'Combine the lighting from image 1 with subject from image 2',
      'The person in image 2 adopts the pose from image 1',
      'Merge the two scenes seamlessly'
    ],
    IMAGE_TO_VIDEO_SINGLE: [
      'Animate this portrait with subtle movements',
      'Make the water flow and clouds move',
      'Create a slow zoom into the subject'
    ],
    IMAGE_TO_VIDEO_TRANSITION: [
      'Smooth transition from day to night',
      'Morph between the two faces',
      'Blend from summer to winter scene'
    ],
    EDIT_THEN_VIDEO: [
      'Change background to beach then create video with transition',
      'Apply sunset lighting and animate with camera movement',
      'Transform style to cinematic and add motion'
    ]
  };
}

export default {
  analyzeWorkflow,
  getWorkflowExamples,
  AVAILABLE_WORKFLOWS
};
