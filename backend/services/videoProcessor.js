import ffmpeg from 'fluent-ffmpeg';
import ffmpegStatic from 'ffmpeg-static';
import ffprobeStatic from 'ffprobe-static';
import path from 'path';
import fs from 'fs/promises';
import { fileURLToPath } from 'url';
import { v4 as uuidv4 } from 'uuid';
import { getMediaFilePath, getMediaFileUrl, generateUniqueFileName } from '../utils/fileUtils.js';
import { addImageToCurrentCollection } from './collectionManager.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration FFmpeg
ffmpeg.setFfmpegPath(ffmpegStatic);
ffmpeg.setFfprobePath(ffprobeStatic.path || ffprobeStatic);

/**
 * Utilitaire pour cr√©er le dossier temp s'il n'existe pas
 */
async function ensureTempDir() {
  const tempDir = path.join(process.cwd(), 'uploads', 'temp');
  try {
    await fs.mkdir(tempDir, { recursive: true });
    return tempDir;
  } catch (error) {
    console.error('Erreur cr√©ation dossier temp:', error);
    throw error;
  }
}

/**
 * Extraire une frame d'une vid√©o
 * @param {Object} params - Param√®tres d'extraction
 * @param {string|Buffer} params.video - Chemin vers la vid√©o ou Buffer
 * @param {string} [params.frameType='first'] - Type de frame: 'first', 'last', 'middle', 'time'
 * @param {string} [params.timeCode='00:00:01'] - Temps sp√©cifique pour frameType='time'
 * @param {string} [params.outputFormat='jpg'] - Format de sortie: jpg, png, webp
 * @param {number} [params.quality=95] - Qualit√© de l'image (1-100)
 * @returns {Promise<Object>} R√©sultat avec le chemin de l'image extraite
 */
export async function extractVideoFrame({
  video,
  frameType = 'first',
  timeCode = '00:00:01',
  outputFormat = 'jpg',
  quality = 95
}) {
  try {
    global.logWorkflow('üé¨ Extraction de frame vid√©o', {
      frameType,
      timeCode,
      outputFormat,
      quality,
      hasVideo: !!video
    });

    const tempDir = await ensureTempDir();
    const outputFilename = generateUniqueFileName(outputFormat);
    const outputPath = getMediaFilePath(outputFilename);

    // G√©rer le cas o√π video est un Buffer (upload direct)
    let videoPath = video;
    let tempVideoPath = null;
    
    if (Buffer.isBuffer(video)) {
      // Buffer ‚Üí fichier temporaire
      tempVideoPath = path.join(tempDir, `temp_video_${uuidv4()}.mp4`);
      await fs.writeFile(tempVideoPath, video);
      videoPath = tempVideoPath;
    } else if (typeof video === 'object' && video.url) {
      // Objet avec url ‚Üí extraire et convertir en chemin absolu si n√©cessaire
      const url = video.url;
      if (url.startsWith('/medias/')) {
        videoPath = path.join(__dirname, '..', url);
        global.logWorkflow('üìÅ Lecture vid√©o locale depuis objet', { url, videoPath });
      } else {
        videoPath = url;
      }
    } else if (typeof video === 'object' && video.path) {
      // Objet avec path ‚Üí utiliser le path
      videoPath = video.path;
      global.logWorkflow('üìÅ Utilisation path direct', { videoPath });
    } else if (typeof video === 'string' && video.startsWith('/medias/')) {
      // Chemin local /medias/... ‚Üí chemin absolu
      videoPath = path.join(__dirname, '..', video);
      global.logWorkflow('üìÅ Lecture vid√©o locale', { videoPath });
    }

    // Obtenir les m√©tadonn√©es pour calculer les timestamps
    const metadata = await getVideoMetadata(videoPath);
    const duration = metadata.duration;

    let seekTime = 0;

    switch (frameType) {
      case 'first':
        seekTime = 0;
        break;
      case 'last':
        seekTime = Math.max(0, duration - 0.1);
        break;
      case 'middle':
        seekTime = duration / 2;
        break;
      case 'time':
        // Convertir timeCode en secondes si c'est un format HH:MM:SS
        if (typeof timeCode === 'string' && timeCode.includes(':')) {
          const parts = timeCode.split(':');
          seekTime = parseInt(parts[0]) * 3600 + parseInt(parts[1]) * 60 + parseFloat(parts[2]);
        } else {
          seekTime = parseFloat(timeCode);
        }
        break;
      default:
        throw new Error(`Type de frame non support√©: ${frameType}`);
    }

    // S'assurer que le temps ne d√©passe pas la dur√©e de la vid√©o
    seekTime = Math.min(seekTime, duration - 0.1);

    return new Promise((resolve, reject) => {
      ffmpeg(videoPath)
        .seekInput(seekTime)
        .frames(1)
        .output(outputPath)
        .outputOptions([
          `-q:v ${Math.round((100 - quality) / 4)}`, // Conversion qualit√© FFmpeg (2-31, 2=meilleure)
          '-update 1'
        ])
        .on('end', async () => {
          // Nettoyer le fichier vid√©o temporaire si c'√©tait un Buffer
          if (tempVideoPath) {
            try {
              await fs.unlink(tempVideoPath);
            } catch (error) {
              console.warn('Impossible de supprimer le fichier vid√©o temporaire:', error.message);
            }
          }

          global.logWorkflow('‚úÖ Frame extraite avec succ√®s', {
            outputPath,
            frameType,
            seekTime: `${seekTime.toFixed(2)}s`,
            videoDuration: `${duration.toFixed(2)}s`
          });

          // Ajouter la frame extraite √† la collection courante
          try {
            // Extraire le mediaId depuis le filename (format: UUID.ext)
            const mediaId = outputFilename.split('.')[0];
            
            await addImageToCurrentCollection({
              url: `/medias/${outputFilename}`, // URL relative
              mediaId: mediaId, // UUID de l'image
              type: 'image', // Type image
              description: `Frame extraite (${frameType}) √† ${formatTime(seekTime)}`,
              metadata: {
                extractedFrom: 'video',
                frameType: frameType,
                timestamp: seekTime.toFixed(2) + 's',
                videoDuration: duration.toFixed(2) + 's',
                format: outputFormat,
                quality: quality
              }
            });
            
            global.logWorkflow('üíæ Frame ajout√©e √† la collection courante', {
              filename: outputFilename,
              frameType,
              timestamp: formatTime(seekTime)
            });
          } catch (collectionError) {
            console.warn('‚ö†Ô∏è Impossible d\'ajouter la frame √† la collection:', collectionError.message);
          }

          resolve({
            success: true,
            image_path: outputPath,
            image_url: getMediaFileUrl(outputFilename),
            frame_info: {
              type: frameType,
              timestamp: seekTime,
              timeCode: formatTime(seekTime),
              video_duration: duration,
              format: outputFormat,
              quality: quality
            },
            file_info: {
              filename: outputFilename,
              path: outputPath
            }
          });
        })
        .on('error', (error) => {
          global.logWorkflow('‚ùå Erreur extraction frame', {
            error: error.message,
            frameType,
            seekTime
          });
          reject(error);
        })
        .run();
    });

  } catch (error) {
    global.logWorkflow('‚ùå Erreur dans extractVideoFrame', {
      error: error.message,
      frameType,
      timeCode
    });
    throw error;
  }
}

/**
 * Concat√©ner plusieurs vid√©os
 * @param {Object} params - Param√®tres de concat√©nation
 * @param {Array<string|Buffer>} params.videos - Liste des vid√©os √† concat√©ner
 * @param {string} [params.outputFormat='mp4'] - Format de sortie
 * @param {string} [params.resolution=null] - R√©solution forc√©e (ex: '1920x1080')
 * @param {number} [params.fps=null] - FPS forc√©
 * @param {string} [params.quality='medium'] - Qualit√©: 'low', 'medium', 'high'
 * @returns {Promise<Object>} R√©sultat avec le chemin de la vid√©o concat√©n√©e
 */
export async function concatenateVideos({
  videos,
  outputFormat = 'mp4',
  resolution = null,
  fps = null,
  quality = 'medium'
}) {
  try {
    global.logWorkflow('üé¨ Concat√©nation de vid√©os', {
      videoCount: videos?.length || 0,
      outputFormat,
      resolution,
      fps,
      quality
    });

    if (!videos || videos.length < 2) {
      throw new Error('Au moins 2 vid√©os sont requises pour la concat√©nation');
    }

    const tempDir = await ensureTempDir();
    const outputFilename = generateUniqueFileName(outputFormat);
    const outputPath = getMediaFilePath(outputFilename);

    // Traiter les vid√©os (Buffer ‚Üí fichiers temporaires)
    const tempVideoPaths = [];
    const videoInfos = [];

    for (let i = 0; i < videos.length; i++) {
      const video = videos[i];
      let videoPath;

      if (Buffer.isBuffer(video)) {
        videoPath = path.join(tempDir, `temp_video_${i}_${uuidv4()}.mp4`);
        await fs.writeFile(videoPath, video);
        tempVideoPaths.push(videoPath);
      } else {
        videoPath = video;
      }

      // Obtenir les infos de chaque vid√©o
      const metadata = await getVideoMetadata(videoPath);
      videoInfos.push({
        path: videoPath,
        duration: metadata.duration,
        width: metadata.video?.width,
        height: metadata.video?.height,
        fps: metadata.video?.fps,
        hasAudio: !!metadata.audio  // V√©rifier si la vid√©o a de l'audio
      });
    }

    global.logWorkflow('üìä Infos vid√©os √† concat√©ner', {
      videos: videoInfos.map((info, i) => ({
        index: i,
        duration: `${info.duration.toFixed(2)}s`,
        resolution: `${info.width}x${info.height}`,
        fps: info.fps,
        hasAudio: info.hasAudio
      }))
    });

    // D√©terminer la r√©solution cible
    let targetWidth = resolution ? parseInt(resolution.split('x')[0]) : Math.max(...videoInfos.map(v => v.width || 0));
    let targetHeight = resolution ? parseInt(resolution.split('x')[1]) : Math.max(...videoInfos.map(v => v.height || 0));

    // Si pas de r√©solution sp√©cifi√©e, utiliser la plus commune
    if (!resolution) {
      const resolutions = videoInfos.map(v => `${v.width}x${v.height}`);
      const mostCommon = resolutions.sort((a, b) =>
        resolutions.filter(v => v === a).length - resolutions.filter(v => v === b).length
      ).pop();
      [targetWidth, targetHeight] = mostCommon.split('x').map(Number);
    }

    // Param√®tres de qualit√©
    const qualitySettings = {
      low: { crf: 28, preset: 'veryfast' },
      medium: { crf: 23, preset: 'medium' },
      high: { crf: 18, preset: 'slow' }
    };
    const { crf, preset } = qualitySettings[quality] || qualitySettings.medium;

    return new Promise((resolve, reject) => {
      let command = ffmpeg();

      // Ajouter toutes les vid√©os en input
      videoInfos.forEach(info => {
        command = command.input(info.path);
      });

      // V√©rifier si au moins une vid√©o a de l'audio
      const hasAnyAudio = videoInfos.some(info => info.hasAudio);

      // Cr√©er le filtre complexe pour normaliser et concat√©ner
      const videoFilters = videoInfos.map((_, i) => 
        `[${i}:v]scale=${targetWidth}:${targetHeight}:force_original_aspect_ratio=decrease,pad=${targetWidth}:${targetHeight}:(ow-iw)/2:(oh-ih)/2,setsar=1,fps=${fps || 30}[v${i}]`
      );
      
      let filterComplex;
      let outputOptions;

      if (hasAnyAudio) {
        // Si au moins une vid√©o a de l'audio, traiter l'audio
        const audioFilters = videoInfos.map((info, i) => {
          if (info.hasAudio) {
            return `[${i}:a]aformat=sample_rates=48000:channel_layouts=stereo[a${i}]`;
          } else {
            // Cr√©er une piste audio silencieuse pour les vid√©os sans audio
            return `anullsrc=channel_layout=stereo:sample_rate=48000[a${i}]`;
          }
        });

        const concatFilter = `${videoInfos.map((_, i) => `[v${i}][a${i}]`).join('')}concat=n=${videoInfos.length}:v=1:a=1[outv][outa]`;

        filterComplex = [
          ...videoFilters,
          ...audioFilters,
          concatFilter
        ];

        outputOptions = [
          '-map [outv]',
          '-map [outa]',
          '-c:v libx264',
          '-c:a aac',
          `-crf ${crf}`,
          `-preset ${preset}`,
          '-movflags +faststart'
        ];
      } else {
        // Aucune vid√©o n'a d'audio - concat√©nation vid√©o uniquement
        const concatFilter = `${videoInfos.map((_, i) => `[v${i}]`).join('')}concat=n=${videoInfos.length}:v=1:a=0[outv]`;

        filterComplex = [
          ...videoFilters,
          concatFilter
        ];

        outputOptions = [
          '-map [outv]',
          '-c:v libx264',
          `-crf ${crf}`,
          `-preset ${preset}`,
          '-movflags +faststart'
        ];
      }

      command
        .complexFilter(filterComplex)
        .outputOptions(outputOptions)
        .output(outputPath)
        .on('progress', (progress) => {
          const percent = Math.round(progress.percent || 0);
          if (percent % 10 === 0) { // Log tous les 10%
            global.logWorkflow(`üé¨ Concat√©nation: ${percent}%`);
          }
        })
        .on('end', async () => {
          // Nettoyer les fichiers temporaires
          for (const tempPath of tempVideoPaths) {
            try {
              await fs.unlink(tempPath);
            } catch (error) {
              console.warn('Impossible de supprimer le fichier temporaire:', error.message);
            }
          }

          // Obtenir les infos du fichier final
          const finalMetadata = await getVideoMetadata(outputPath);
          const totalDuration = videoInfos.reduce((sum, info) => sum + info.duration, 0);

          global.logWorkflow('‚úÖ Concat√©nation termin√©e', {
            inputCount: videos.length,
            totalInputDuration: `${totalDuration.toFixed(2)}s`,
            outputDuration: `${finalMetadata.duration.toFixed(2)}s`,
            outputResolution: `${targetWidth}x${targetHeight}`,
            outputFile: outputFilename
          });

          resolve({
            success: true,
            video_path: outputPath,
            video_url: getMediaFileUrl(outputFilename),
            concat_info: {
              input_count: videos.length,
              total_duration: finalMetadata.duration,
              resolution: `${targetWidth}x${targetHeight}`,
              fps: fps || 30,
              format: outputFormat,
              quality: quality
            },
            input_videos: videoInfos.map((info, i) => ({
              index: i,
              duration: info.duration,
              resolution: `${info.width}x${info.height}`
            })),
            file_info: {
              filename: outputFilename,
              path: outputPath,
              size_mb: Math.round((await fs.stat(outputPath)).size / (1024 * 1024) * 100) / 100
            }
          });
        })
        .on('error', async (error) => {
          // Nettoyer en cas d'erreur
          for (const tempPath of tempVideoPaths) {
            try {
              await fs.unlink(tempPath);
            } catch (e) {
              // Ignorer les erreurs de nettoyage
            }
          }

          global.logWorkflow('‚ùå Erreur concat√©nation', {
            error: error.message,
            videoCount: videos.length
          });
          reject(error);
        })
        .run();
    });

  } catch (error) {
    global.logWorkflow('‚ùå Erreur dans concatenateVideos', {
      error: error.message,
      videoCount: videos?.length || 0
    });
    throw error;
  }
}

/**
 * Obtenir les m√©tadonn√©es d'une vid√©o
 * @param {string} videoPath - Chemin vers la vid√©o
 * @returns {Promise<Object>} M√©tadonn√©es de la vid√©o
 */
export async function getVideoMetadata(videoPath) {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(videoPath, (err, metadata) => {
      if (err) return reject(err);

      const videoStream = metadata.streams.find(stream => stream.codec_type === 'video');
      const audioStream = metadata.streams.find(stream => stream.codec_type === 'audio');

      resolve({
        success: true,
        duration: metadata.format.duration,
        size: metadata.format.size,
        bitRate: metadata.format.bit_rate,
        format: metadata.format.format_name,
        video: videoStream ? {
          codec: videoStream.codec_name,
          width: videoStream.width,
          height: videoStream.height,
          fps: videoStream.r_frame_rate ? eval(videoStream.r_frame_rate) : null,
          pixelFormat: videoStream.pix_fmt,
          bitRate: videoStream.bit_rate
        } : null,
        audio: audioStream ? {
          codec: audioStream.codec_name,
          sampleRate: audioStream.sample_rate,
          channels: audioStream.channels,
          bitRate: audioStream.bit_rate
        } : null
      });
    });
  });
}

/**
 * Formater un temps en secondes vers HH:MM:SS
 * @param {number} seconds - Temps en secondes
 * @returns {string} Temps format√©
 */
function formatTime(seconds) {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const ms = Math.floor((seconds % 1) * 100);
  
  return `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}.${ms.toString().padStart(2, '0')}`;
}

/**
 * Valider les param√®tres d'extraction de frame
 * @param {Object} params - Param√®tres √† valider
 * @returns {Object} { isValid, errors }
 */
export function validateExtractFrameParams(params) {
  const errors = [];

  if (!params.video) {
    errors.push('Vid√©o requise');
  }

  const validFrameTypes = ['first', 'last', 'middle', 'time'];
  if (params.frameType && !validFrameTypes.includes(params.frameType)) {
    errors.push(`Type de frame invalide. Valeurs accept√©es: ${validFrameTypes.join(', ')}`);
  }

  const validFormats = ['jpg', 'png', 'webp'];
  if (params.outputFormat && !validFormats.includes(params.outputFormat)) {
    errors.push(`Format de sortie invalide. Valeurs accept√©es: ${validFormats.join(', ')}`);
  }

  if (params.quality && (typeof params.quality !== 'number' || params.quality < 1 || params.quality > 100)) {
    errors.push('La qualit√© doit √™tre un nombre entre 1 et 100');
  }

  return {
    isValid: errors.length === 0,
    errors
  };
}

/**
 * Valider les param√®tres de concat√©nation
 * @param {Object} params - Param√®tres √† valider
 * @returns {Object} { isValid, errors }
 */
export function validateConcatenateParams(params) {
  const errors = [];

  if (!params.videos || !Array.isArray(params.videos) || params.videos.length < 2) {
    errors.push('Au moins 2 vid√©os sont requises');
  }

  const validFormats = ['mp4', 'mov', 'avi', 'mkv'];
  if (params.outputFormat && !validFormats.includes(params.outputFormat)) {
    errors.push(`Format de sortie invalide. Valeurs accept√©es: ${validFormats.join(', ')}`);
  }

  const validQualities = ['low', 'medium', 'high'];
  if (params.quality && !validQualities.includes(params.quality)) {
    errors.push(`Qualit√© invalide. Valeurs accept√©es: ${validQualities.join(', ')}`);
  }

  if (params.fps && (typeof params.fps !== 'number' || params.fps < 1 || params.fps > 120)) {
    errors.push('Le FPS doit √™tre un nombre entre 1 et 120');
  }

  return {
    isValid: errors.length === 0,
    errors
  };
}

export default {
  extractVideoFrame,
  concatenateVideos,
  getVideoMetadata,
  validateExtractFrameParams,
  validateConcatenateParams
};